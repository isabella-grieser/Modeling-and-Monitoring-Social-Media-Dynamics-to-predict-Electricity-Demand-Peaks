\chapter{Implementation of a Framework to model the Effect
of Information on Social Media on the Power Grid}

In this Chapter, a framework to analyse and predict 
the effects of information on the 
power grid will be introduced and the specific implementation of the 
framework will be explained.
First, in Section \ref{simulationframeworksection}, 
the implementation of the simulation framework will described.
In Section \ref{modelsocialnetwork}, the underlying social network model
used in the simulation is described. Then, in Section 
\ref{modelinformationdiffusion}, the algorithm used to model
the information diffusion process in the social network is 
defined. Next, in Section \ref{rulebasedpowerconsumption}, 
the rules to model the additional power consumption is explained.
In addition, in Section \ref{parameterestimationalgo},
an parameter estimation algorithm to estimate realistic 
values for the simulation parameters is introduced and 
the different steps of the framework are described.

\section{Implementation of the Simulation Framework}
\label{simulationframeworksection}
There are multiple components that are essential to model the effects of 
both true and false information on critical infrastructures
such as the power grid. The development of the simulation framework
proposed in this work can be divided into three parts. First, it is 
necessary to model a social media network graph with characteristics similar 
or equal to
real social media networks. Second, an algorithm to model the 
propagation of information over the network needs to be defined and 
implemented. Third, rules to estimate the changes in the power consumption 
need to be defined and a general simulation algorithm needs to be implemented.

\subsection{Modelling Social Networks}
\label{modelsocialnetwork}
Two potential approaches exist to create social media network graphs 
that can be used in the proposed framework.
% make maybe pretty picture with example graphs for both

First, a real social media network can be used as an example social network
for the purpose of our simulation. 
It is difficult to precisely analyse which real life individuals
control which accounts on social media networks due to privacy reasons.
Thus, it is not possible to create a social network graph that 
correctly shows the real state of the social media network.
Thus, datasets need to be used to model real life networks without 
dealing with privacy concerns. There are datasets available to analyse
real social media networks. One example dataset collection that can 
be used for such a task is the Stanford 
Large Network Dataset Collection \cite{snapnets}.
This collection is part of the Stanford Network Analysis Project (SNAP).
In this collection, there are datasets which show the network structure
of multiple well-known social networks such as Facebook and Twitter.
The advantage of using real social networks as reference networks
for the simulation framework is that real networks fulfill the 
characteristics of social networks the most effectively, since they
are based on real data and not randomly generated. The disadvantage
is that using this approach leads to all simulations using either
one single or few selected social network graph models. Since 
few different graph models are used for consecutive simulations,
it cannot be determined if the simulation results are based on the 
specific structure of the specific social network graph or if the results 
are seasonable for other social networks. Thus, the simulation results
may not be robust. Moreover, the size of the social network graph 
cannot be changed without changing its characteristics, such as 
the clustering coefficient. Since real social network graphs tend to be 
big (for example, the Twitter social network graph provided by SNAP
contains 81306 nodes and the Facebook social network graph contains 
4.039 nodes), it may not be computationally feasible to use such graphs
as reference graphs.

The other approach would be to generate a graph that is not based
on any real social network, but can be used as a reference graph.
For this, the generated graph needs to fulfill the common
characteristics of social networks.
Section \ref{randomgraphssection} introduces multiple random graph algorithms.
Furthermore, in Section \ref{comparison-random-graphs},
these algorithms are evaluated based on how well they fulfill the characteristics
of social networks defined in Section \ref{graphbasics}. 
From the information provided in that Section, it is visible that the 
Barabási–Albert (BA) graph is the random graph algorithm that 
fulfills the characteristics of social networks most effectively. 
Using a random graph to model the social media network brings the advantage
that a variety of different graph models can be generated to use for 
the simulation. Thus, the simulation results can be considered as more 
robust since every simulation can be done with a different underlying 
social media network model. Furthermore, different graph sizes can be 
used in the simulation by changing the amount of nodes to be generated.
Thus, using random graph algorithms is computationally easier since 
real social network graphs tend to be big.
The disadvantage is that random graph models may not fully fulfill
all characteristics of a social network. As mentioned in 
Section \ref{comparison-random-graphs}, the BA graph
does not create graphs with a clustering coefficient that is as 
high as real social networks. Nonetheless, the BA  graph is
a graph that is often used to model social networks.
As a conclusion, since the usage of random graphs allows the usage
of unique graph models for the simulation and the size of the 
graph can be changed without changing the graph characteristics, 
the random graph generation approach was used to model social networks.

\subsection{Implementation of the Information Propagation Algorithm}
\label{modelinformationdiffusion}

There are multiple methods to model information diffusion in graph models.
In Section \ref{informationdiffsection}, three different information diffusion
model algorithms were introduced.
Both the information cascade model and the threshold model focus on the 
information diffusion process itself and not on the change in behavior
of the single entities in the system. Thus, in these two models,
entities may have two states: 
\textit{Informed} and \textit{Not Informed}.
On the other hand, epidemiological models such as the SIR model
focus on the changes of the states of the entities in the system.
Thus, it is possible to define a variety of behaviors in the
information diffusion progress with epidemiological models. 
In this Thesis, we are interested in both how the information
diffuses and how it could be combated by using fact-checking.
This can be studied in more detail if entities can 
show different behaviors depending on what kind of information
they possess. This can only be done in epidemiological models.
Thus, an epidemiological model was chosen to model the information 
diffusion process.

%say I want epidemological model

Epidemiological models generally defined by differential equations.
As an example, the differential equations for the SIR and SIS 
model are shown in Table \ref{SI-table-equations}.
Nonetheless, graph-based epidemological models are also used.
In Section \ref{epidemologicalmodels}, an information 
diffusion model based on the work of \textit{Tambuscio et al.} 
\cite{sirsmodel} is introduced. It has the advantage of being 
able to model both the misinformation and fact-checking 
diffusion process in the same model. 
For this Thesis, the the model of \textit{Tambuscio et al.} was
modified to deal with a differing assumption.
In this work, we only consider the short-term effects of the information 
on the power grid. Recurring spread of the same misinformation
is not considered in this Thesis. This is done because it can be 
assumed that the initial spread of the information leads to the 
greatest effect on the power grid since it is also assumed that this
spread leads to the greatest amount of infected entities at
the time $t_{max,I}$. Thus, we can declare $p_{\mathrm{forget}} = 0$.
This assumption leads to a modified state chart and probability
functions compared to \textit{Tambuscio et al.}. The modified
state chart can be seen in Figure \ref{modifiedmodelstatechart}
and the modified probability functions can be seen in Table
\ref{modified-SIS-table-equations}. In Figure 
\ref{modifiedmodelstatechart}, it can be observed that 
$p_{\mathrm{forget}} = 0$. Thus, there is no transition back to 
the state \textit{Susceptible} and all entities
will inevitably transition to the \textit{Recovered} state. 
In conclusion, the modified model can be categorized as a SIR model. 


\begin{figure}[!ht]
    \center
    \includegraphics[scale=.9]{figs/Tambuscio_modified.png}
    \caption{state chart for the modified model}
    \label{modifiedmodelstatechart}
\end{figure}

\begin{table}[ht!]
    \centering
    \begin{tabular}{|c  c |} 
     \hline
     & \\
     $\begin{aligned}
          p_i^S(t+1) &= (1-f_i-g_i)s_i^S(t) \\
          p_i^I(t+1) &= f_is_i^S(t) + (1-p_{verify})s_i^I(t) \\
          p_i^R(t+1) &= g_is_i^S(t) + p_{verify}s_i^I(t)+s_i^R(t)
        \end{aligned}$
      &
      $\begin{aligned}
          f_i(t) &= \beta \frac{n_i^I(t)(1+\alpha)}{n_i^I(t)(1+\alpha)+n_i^R(t)(1-\alpha)} \\
          g_i(t) &= \beta \frac{n_i^R(t)(1-\alpha)}{n_i^I(t)(1+\alpha)+n_i^R(t)(1-\alpha)} \\
        \end{aligned}$
       \\ 
       & \\
     \hline
    \end{tabular}
    \caption{modified probability functions for the states}
    \label{modified-SIS-table-equations}
\end{table}

\subsection{Rule-based Calculation of the Power Consumption}
\label{rulebasedpowerconsumption}

\section{Extending the Framework to estimate the System Parameters based on
Domain Variables}
\label{parameterestimationalgo}

In Section \ref{simulationframeworksection}, a framework to simulate the effects 
of information on the power grid was introduced. However, the simulation results
may differ significantly based on which parameters were chosen for the simulation.
Furthermore, if the systems parameters are chosen without any real-life basis,
the result of the simulation may be unrealistic. Thus, the simulation framework 
may not be useful to predict possible crisis scenarios.
As a consequence, if the framework should produce realistic results and if
it should be used to possibly predict excess power consumption, an 
algorithm to estimate realistic values for the system parameters is necessary.

In Section \ref{powerloadsection}, different possible variables that 
correlate with power load were introduced. These variables could be 
used to estimate realistic system parameters. For this Thesis, social media data is 
used to estimate the system parameters that control the 
information propagation. Since it is difficult to get highly personalized 
information of people on the internet because of data privacy reasons, the
social media data is assumed to be as generalized as possible and the identity 
of the users posting messages is assumed to be unknown. The only information
that is being considered in this Thesis are the messages itself.
One method to estimate the propagation parameters of the SIR model 
is to view the problem as a minimization problem 
\cite{jin2013epidemiological}. The idea is to iteratively solve the differential 
equations of the SIR model, analyse the infection process and minimize 
its difference of the true infection process that can be seen via the
social media data. A simplified diagram with the steps of the algorithm
can be seen in Figure \ref{paramestimationbasic}. The method that is proposed 
in this Thesis contains five different steps. 
The first three steps are used to gather and preprocess 
the data that is of relevance for the parameter estimation process.
The last two steps make up the parameter estimation algorithm.
The steps in the proposed method are:

\begin{enumerate}
    \item Find all relevant posts and messages on social media websites.
    This can be done with both natural language processing techniques and
    by using keyword search queries.
    \item Count the amount of relevant social media posts over a given 
    timespan. This is done by counting the amount of posts in given intervals, 
    such as e.g. the amount of posts each 15 minutes. This data shows the
    engagement on the specific topic over time.
    \item Filter the data graph to smoothen the data and to facilitate the
    parameter extraction process. The filtered data is $posts(t)$.
    \item Initialize the minimization algorithm with predefined unknown
    variables and their initial values. Optimize the variables
    so that the difference of the curve progression of the SIR model
    and the number of posts over time is minimized. For each minimization
    step, the differential equations that define the infection progression
    in the system need to be solved.
\end{enumerate}

\begin{figure}[!ht]
    \center
    \includegraphics[scale=.65]{figs/parameter_estimation_process.png}
    \caption{Steps of the parameter estimation algorithm}
    \label{paramestimationbasic}
\end{figure}

To use the algorithm proposed in this Thesis, it is necessary to 
know the specific differential equations that describe the propagation 
process over time in the system. However, the propagation algorithm
used in the simulation framework is not based on differential equations,
but is a graph-based algorithm. Since it is graph-based, the propagation algorithm
does not provide a system-wide view on the propagation process,
it only considers the local status of the infection, i.e the neighbors
of each node, to decide on the state of a specific node.
To calculate the differential equations for the specific SIR model algorithm
used in this Thesis, mean-field theory is used to generalize the equations
\cite{chaikin1995principles}.
This is done by averaging certain variables in the system, making these
variables constant over the whole system and thus 
reducing the degrees of freedom that need to be considered.
Thus, all unique interactions in a system are averaged into a simpler,
higher-level or system-wide view.
This approach originated from molecular analysis, where the method is used
to average the behaviors of many molecules into the average behavior
of the whole system,
but it can also be used to analyse the characteristics of graphs
\cite{barabasi1999mean}\cite{sirsmodel}.
Thus, mean-field theory is used in this Thesis to 
analyse the average interactions in the graph and thus to deduce 
the average characteristics of the information 
propagation process. 

To analyse the average information propagation process, 
it can be assumed that for a Barabási–Albert random graph, 
the median degree for a node in the graph will be equal to the amount 
of edges generated when adding a new node to the random graph.
This assumption can be made since the graph follows the power law distribution,
which defines that few nodes have a high amount of connections to other nodes
and a high amount of nodes have comparatively low amount of connections to 
other nodes. Since the minimum amount of edges that a node can have 
in the Barabási–Albert random graph generation algorithm is $k$, this 
means that we can assume that $\forall i \to c_i=k$.
Next, we define that $S(t), I(t), R(t)$, where $S(t)$ is the amount of
entities in the system with the status \textit{Susceptible} at the time $t$, 
$I(t)$ is the amount of entities with the status \textit{Infected} and
$R(t)$ is the amount of entities with the status \textit{Recovered}. 
We assume that the states of the neighbors of a node $i$ at the time $t$ are 
randomly distributed given the probabilities $p^S(t), p^I(t), p^R(t)$,
where $p^S(t) + p^I(t) + p^R(t) = 1$. We can calculate the values $S, I, R$
with the Equations in \ref{SIR-system-amound-eqs:all-lines},
with $N$ as the total amount of entities in the system.

\begin{subequations}
\begin{align}
    S(t) &=p^S(t)\cdot N \label{SIR-system-amound-eqs:1}\\
    I(t) &=p^I(t)\cdot N \label{SIR-system-amound-eqs:2}\\
    R(t) &=p^R(t)\cdot N \label{SIR-system-amound-eqs:3}
\end{align}
\label{SIR-system-amound-eqs:all-lines}
\end{subequations}

Given the Equations in \ref{SIR-system-amound-eqs:all-lines}, it is also possible 
to calculate the changes $\Delta S(t), \Delta I(t), \Delta R(t)$ between each 
iteration step $t$ and $t+1$ in the system.
The changes can be calculated with the Equations defined in 
\ref{SIR-diff-system-amount-eqs}.

\begin{subequations}
\begin{align}
    \frac{dS}{dt} \approx \frac{\Delta S(t)}{\Delta t} = \frac{\Delta S(t)}{1} = \Delta S(t) &=\Delta p^S(t)\cdot N \label{SIR-diff-system-amount-eqs:1}\\
    \frac{dI}{dt} \approx \frac{\Delta I(t)}{\Delta t} = \frac{\Delta I(t)}{1} = \Delta I(t) &=\Delta p^I(t)\cdot N \label{SIR-diff-system-amount-eqs:2}\\
    \frac{dR}{dt} \approx \frac{\Delta R(t)}{\Delta t} = \frac{\Delta R(t)}{1} = \Delta R(t) &=\Delta p^R(t)\cdot N \label{SIR-diff-system-amount-eqs:3}
\end{align}
\label{SIR-diff-system-amount-eqs}
\end{subequations}

Since we assume that the states are randomly distributed over the system, 
we consequently assume that the state of the node $i$ is randomly distributed.
Thus, the state $s_i$ of the node $i$ can be defined as in Equation 
\ref{state-node-equation}.

\begin{equation}
    s_i = [s_i^S, s_i^I, s_i^R] = [p^S(t), p^I(t), p^R(t)]
    \label{state-node-equation}
\end{equation}

Furthermore, the functions $g_i,f_i$ defined in Table 
\ref{modified-SIS-table-equations}
can be generalized by assuming that the average amount of neighbors 
of a specific state $K$ can be calculated as $k\cdot p^K(t)$. For this
assumption, $k$ is the median degree of all nodes and $p^K(t)$ is the 
average probability that a node is in the state $K$.
Thus, the functions $g_i,f_i$ can be generalized as in
Equations \ref{generalized-functions-g-f}.

\begin{subequations}
\begin{align}
    f_i(t) &= \beta \frac{n_i^I(t)(1+\alpha)}{n_i^I(t)(1+\alpha)+n_i^R(t)(1-\alpha)} 
    \nonumber\\
    \to f(t) &= k\beta \frac{p^I(t)(1+\alpha)}{p^I(t)(1+\alpha)+p^R(t)(1-\alpha)}
    \label{generalized-function-f} \\
    g_i(t) &= \beta \frac{n_i^F(t)(1-\alpha)}{n_i^I(t)(1+\alpha)+n_i^R(t)(1-\alpha)} 
    \nonumber \\
    \to g(t) &= k\beta \frac{p^F(t)(1-\alpha)}{p^I(t)(1+\alpha)+p^R(t)(1-\alpha)}
    \label{generalized-function-g}
\end{align}
\label{generalized-functions-g-f}
\end{subequations}

With these assumptions, the general equations for the SIR model can 
be deduced. First, the function for $\Delta R(t)$ can be infered
as shown in Equation \ref{delta-r-deduction-eqs}.

\begin{align}
    p^R(t+1) &= g \cdot p^S(t) + p_{verify}\cdot p^I(t) + p^R(t) \nonumber\\
    p^R(t+1) - p^R(t) &= g \cdot p^S(t) + p_{verify}\cdot p^I(t) \nonumber\\
    \Delta R(t) = (p^R(t+1) - p^R(t))\cdot N 
    &= N(g \cdot p^S(t) + p_{verify}\cdot p^I(t)) \nonumber\\
    &= N(g \cdot \frac{S(t)}{N} + p_{verify}\cdot \frac{I}{N} ) \nonumber\\
    &= g \cdot S(t) + p_{verify}\cdot I(t) \nonumber\\
    &= k\beta \frac{p^R(t)(1-\alpha)}{p^I(t)(1+\alpha)+p^R(t)(1-\alpha)} 
    \cdot S(t) + p_{verify}\cdot I(t) \nonumber\\
    &= k\beta \frac{\frac{R(t)}{N}(1-\alpha)}{\frac{I(t)}{N}(1+\alpha)+\frac{R(t)}{N}(1-\alpha)} 
    \cdot S(t) + p_{verify}\cdot I(t) \nonumber\\
    \Delta R(t) &= \frac{k\beta}{N} \frac{R(t)(1-\alpha)}{I(t)(1+\alpha)+R(t)(1-\alpha)} 
    \cdot S(t) + p_{verify}\cdot I(t) \label{delta-r-deduction-eqs}
\end{align}

The equation for $\Delta I(t)$ can be infered in a similar manner to $\Delta R(t)$.
The deduction steps for $\Delta I(t)$ are shown in Equation 
\ref{delta-i-deduction-eqs}.

\begin{align}
    p^I(t+1) &= f \cdot p^S(t) + (1 - p_{verify})\cdot p^I(t) \nonumber\\
     &= f \cdot p^S(t) + p^I(t) - p_{verify}\cdot p^I(t) \nonumber\\
    p^I(t+1) - p^I(t) &= f \cdot p^S(t) - p_{verify}\cdot p^I(t) \nonumber\\
    \Delta I(t) = (p^I(t+1) - p^I(t)) \cdot N 
    &= N (f \cdot p^S(t) - p_{verify}\cdot p^I(t)) \nonumber\\
    &= N (f \cdot \frac{S(t)}{N}  - p_{verify}\cdot \frac{I(t)}{N}) \nonumber\\
    &= f \cdot S(t) - p_{verify}\cdot I(t) \nonumber\\
    &=  k\beta \frac{p^I(t)(1+\alpha)}{p^I(t)(1+\alpha)+p^R(t)(1-\alpha)}
     \cdot S(t) - p_{verify}\cdot I(t) \nonumber\\
    &=  k\beta \frac{\frac{B(t)}{N}(1+\alpha)}{\frac{I(t)}{N}(1+\alpha)+\frac{R(t)}{N}(1-\alpha)}
     \cdot S(t) - p_{verify}\cdot I(t) \nonumber\\
     \Delta I(t) &=  \frac{k\beta}{N} \frac{I(t)(1+\alpha)}{I(t)(1+\alpha)+R(t)(1-\alpha)}
     \cdot S(t) - p_{verify}\cdot I(t) \label{delta-i-deduction-eqs}
\end{align}

Last, given that there are no entities entering or leaving the system,
it can be assumed that the state changes in the system all sum to zero,
thus $\Delta S(t)+ \Delta I(t)+ \Delta R(t) = 0$. With this, the equation for
$\Delta S$ can be deduced as shown in Equation \ref{delta-s-deduction-eqs}.

\begin{align}
    \Delta S(t) &= - \Delta I(t) - \Delta R(t) \nonumber\\
     &= -\frac{k\beta}{N} \frac{I(t)(1+\alpha)}{B(t)(1+\alpha)+R(t)(1-\alpha)}
     \cdot S(t) + p_{verify}\cdot I(t) \nonumber\\
      & -\frac{k\beta}{N} \frac{R(t)(1-\alpha)}{B(t)(1+\alpha)+R(t)(1-\alpha)} 
      \cdot S(t) - p_{verify}\cdot I(t) \nonumber\\
      &= -\frac{k\beta}{N} \frac{I(t)(1+\alpha) + R(t)(1-\alpha)}{I(t)(1+\alpha)+R(t)(1-\alpha)}
      \cdot S(t) + p_{verify}\cdot I(t) - p_{verify}\cdot I(t) \nonumber\\
      &= -\frac{k\beta}{N} \frac{I(t)(1+\alpha) + R(t)(1-\alpha)}{I(t)(1+\alpha)+R(t)(1-\alpha)}
      \cdot S(t) \nonumber\\
      \Delta S(t) &= -\frac{k\beta}{N} \cdot S(t) \label{delta-s-deduction-eqs}
\end{align}


Summarized, the differential equations that are used for the parameter estimation 
algorithm can be seen in Equation \ref{all-deduced-diff-equations}.

\begin{subequations}
    \begin{align}
        \frac{dS}{dt} \approx \Delta S(t) &= -\frac{k\beta}{N} \cdot S(t) \\
        \frac{dI}{dt} \approx  \Delta I(t) &=  \frac{k\beta}{N} \frac{I(t)(1+\alpha)}{I(t)(1+\alpha)+R(t)(1-\alpha)}
        \cdot S(t) - p_{verify}\cdot I(t) \\
        \frac{dR}{dt} \approx \Delta R(t) &= \frac{k\beta}{N} \frac{R(t)(1-\alpha)}{I(t)(1+\alpha)+R(t)(1-\alpha)} 
        \cdot S(t) + p_{verify}\cdot I(t)\\
\end{align}
\label{all-deduced-diff-equations}
\end{subequations}


The differential equations have multiple unknown variables that need
to be optimized in the minimization process. One unknown variable is
the true size of the system $N$ since $N$ does not need to correlate 
with the size of the social media website $N_{website}$.
Another unknown variable is the average degree $k$ of the social network,
since we do not know the specific characteristics of the network of the
subgroup infected or susceptible to the information.
Next, the two propagation parameters $\alpha, \beta$ are not known
and need to be optimized. 
Last, the initial values $S(t_0), I(t_0), R(t_0)$ are also not known.
Thus, there are seven variables $N, k, \alpha, \beta, S(t_0), I(t_0), R(t_0)$
that need to be optimized.


Next, in conjunction with the simulation framework described in 
\ref{simulationframeworksection}, it should be possible to predict 
a possible overconsumption scenario. For this, a framework
to predict power demand surges started by information shared in 
social media networks is proposed in this Thesis. The steps
in the proposed framework are shown in Figure \ref{basicpredicitonframework}.
First, the data used for the parameter estimation process is gathered and
preprocessed. Then, this data is used for the parameter estimation process
proposed in this Section. Afterwards, the simulation framework is configured
with the parameter estimated in the previous step. For this, 
$\alpha, \beta, S(t_0), I(t_0), R(t_0)$ are used to configure the 
information propagation process implemented in the simulation framework.
The variables $N, k$ are used to configure the random graph generation
characteristics. The implementation of the 
algorithm of the Barabási–Albert random graph in \textit{NetworkX}
receives the total amount of nodes in the graph and the number of edges 
for each incoming node as inputs. Since we assume that the median degree
$k$ equals the number of edges generated for each incoming node, we can thus
use $k$ as an input for the random graph algorithm. However, this assumption
only works if the total amount of nodes in the random graph is $N$.
Since social networks tend to be big, it can be assumed that 
$N$ is of high value and that a graph of such a size may lead to technical 
issues such as high computation time. Thus, smaller values such as $N'$
can be used as long as the ration between the amount of nodes and the
amount of edges for the incoming nodes are the same, thus the constraint
$\frac{k}{N}=\frac{k'}{N'}$ needs to be fulfilled for a Barabási–Albert
graph $G'(N',k')$. With the parameters for the information propagation and 
for the random graph, the simulation can thus be run. 
Last, given the results of the simulation and the power threshold
that define the upper limit of the power grid infrastructure, it
is checked whether the power demand exceeds the predefined threshold.


\begin{figure}[!ht]
    \center
    \includegraphics[scale=.65]{figs/full_prediction_framework.png}
    \caption{Steps of the proposed framework to predict power demand surges
    started by information shared in social media networks}
    \label{basicpredicitonframework}
\end{figure}


% als letzte Idee: herleiten, ab welchen p_verify I_max unter 
% ein bestimmtes threshhold ist